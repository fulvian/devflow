```json
{
  "modifications": [
    {
      "file": "/Users/fulvioventura/devflow/orchestration/task_manager.py",
      "operation": "create",
      "content": "from typing import Dict, List, Optional, Any, Callable\nfrom enum import Enum\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\nimport json\nimport asyncio\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass TaskState(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    BLOCKED = \"blocked\"\n\nclass TaskPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n@dataclass\nclass Task:\n    id: str\n    name: str\n    description: str\n    state: TaskState\n    priority: TaskPriority\n    created_at: datetime\n    updated_at: datetime\n    assigned_agent: Optional[str] = None\n    dependencies: List[str] = None\n    progress: float = 0.0\n    estimated_duration: Optional[int] = None  # in seconds\n    actual_duration: Optional[int] = None  # in seconds\n    failure_reason: Optional[str] = None\n    retry_count: int = 0\n    max_retries: int = 3\n    metadata: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        if self.dependencies is None:\n            self.dependencies = []\n        if self.metadata is None:\n            self.metadata = {}\n\n@dataclass\nclass TaskProgress:\n    task_id: str\n    progress: float\n    timestamp: datetime\n    message: Optional[str] = None\n    resource_utilization: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass Workflow:\n    id: str\n    name: str\n    description: str\n    tasks: List[Task]\n    created_at: datetime\n    updated_at: datetime\n    status: TaskState\n\n@dataclass\nclass AuditTrailEntry:\n    task_id: str\n    timestamp: datetime\n    action: str\n    details: Dict[str, Any]\n    actor: Optional[str] = None\n\nclass TaskManagerSystem:\n    def __init__(self, state_file: str = \"/Users/fulvioventura/devflow/.claude/state/current_task.json\"):\n        self.state_file = state_file\n        self.tasks: Dict[str, Task] = {}\n        self.workflows: Dict[str, Workflow] = {}\n        self.audit_trail: List[AuditTrailEntry] = []\n        self.progress_trackers: Dict[str, List[TaskProgress]] = {}\n        self._load_state()\n    \n    def _load_state(self):\n        \"\"\"Load task state from file\"\"\"\n        try:\n            with open(self.state_file, 'r') as f:\n                data = json.load(f)\n                # Convert loaded data to Task objects\n                for task_id, task_data in data.get('tasks', {}).items():\n                    task_data['state'] = TaskState(task_data['state'])\n                    task_data['priority'] = TaskPriority(task_data['priority'])\n                    task_data['created_at'] = datetime.fromisoformat(task_data['created_at'])\n                    task_data['updated_at'] = datetime.fromisoformat(task_data['updated_at'])\n                    self.tasks[task_id] = Task(**task_data)\n                \n                # Load workflows\n                for workflow_id, workflow_data in data.get('workflows', {}).items():\n                    workflow_data['status'] = TaskState(workflow_data['status'])\n                    workflow_data['created_at'] = datetime.fromisoformat(workflow_data['created_at'])\n                    workflow_data['updated_at'] = datetime.fromisoformat(workflow_data['updated_at'])\n                    workflow_data['tasks'] = [self.tasks[tid] for tid in workflow_data['task_ids'] if tid in self.tasks]\n                    self.workflows[workflow_id] = Workflow(**workflow_data)\n                    \n        except FileNotFoundError:\n            logger.info(\"No existing state file found, starting fresh\")\n        except Exception as e:\n            logger.error(f\"Error loading state: {e}\")\n    \n    def _save_state(self):\n        \"\"\"Save current task state to file\"\"\"\n        try:\n            state_data = {\n                'tasks': {tid: asdict(task) for tid, task in self.tasks.items()},\n                'workflows': {wid: {\n                    'id': workflow.id,\n                    'name': workflow.name,\n                    'description': workflow.description,\n                    'task_ids': [t.id for t in workflow.tasks],\n                    'created_at': workflow.created_at.isoformat(),\n                    'updated_at': workflow.updated_at.isoformat(),\n                    'status': workflow.status.value\n                } for wid, workflow in self.workflows.items()},\n                'audit_trail': [asdict(entry) for entry in self.audit_trail],\n                'progress_trackers': {tid: [asdict(p) for p in progress] for tid, progress in self.progress_trackers.items()}\n            }\n            \n            with open(self.state_file, 'w') as f:\n                json.dump(state_data, f, indent=2)\n        except Exception as e:\n            logger.error(f\"Error saving state: {e}\")\n    \n    def create_task(self, task_id: str, name: str, description: str, \n                   priority: TaskPriority = TaskPriority.MEDIUM,\n                   dependencies: List[str] = None,\n                   estimated_duration: Optional[int] = None,\n                   metadata: Dict[str, Any] = None) -> Task:\n        \"\"\"Create a new task\"\"\"\n        task = Task(\n            id=task_id,\n            name=name,\n            description=description,\n            state=TaskState.PENDING,\n            priority=priority,\n            created_at=datetime.now(),\n            updated_at=datetime.now(),\n            dependencies=dependencies or [],\n            estimated_duration=estimated_duration,\n            metadata=metadata or {}\n        )\n        \n        self.tasks[task_id] = task\n        self.progress_trackers[task_id] = []\n        self._add_audit_entry(task_id, \"task_created\", {\"name\": name, \"priority\": priority.value})\n        self._save_state()\n        \n        return task\n    \n    def create_workflow(self, workflow_id: str, name: str, description: str, task_ids: List[str]) -> Workflow:\n        \"\"\"Create a workflow from existing tasks\"\"\"\n        tasks = [self.tasks[tid] for tid in task_ids if tid in self.tasks]\n        workflow = Workflow(\n            id=workflow_id,\n            name=name,\n            description=description,\n            tasks=tasks,\n            created_at=datetime.now(),\n            updated_at=datetime.now(),\n            status=TaskState.PENDING\n        )\n        \n        self.workflows[workflow_id] = workflow\n        self._add_audit_entry(workflow_id, \"workflow_created\", {\"name\": name, \"task_count\": len(tasks)})\n        self._save_state()\n        \n        return workflow\n    \n    def update_task_state(self, task_id: str, new_state: TaskState, \n                         failure_reason: Optional[str] = None) -> bool:\n        \"\"\"Update task state with validation\"\"\"\n        if task_id not in self.tasks:\n            logger.error(f\"Task {task_id} not found\")\n            return False\n        \n        task = self.tasks[task_id]\n        old_state = task.state\n        \n        # Validate state transition\n        if not self._is_valid_transition(old_state, new_state):\n            logger.error(f\"Invalid state transition from {old_state} to {new_state} for task {task_id}\")\n            return False\n        \n        # Update task\n        task.state = new_state\n        task.updated_at = datetime.now()\n        \n        if new_state == TaskState.FAILED and failure_reason:\n            task.failure_reason = failure_reason\n        \n        # Update workflow status if this task is part of a workflow\n        self._update_workflow_status(task_id)\n        \n        self._add_audit_entry(task_id, \"state_changed\", {\n            \"from\": old_state.value,\n            \"to\": new_state.value,\n            \"failure_reason\": failure_reason\n        })\n        self._save_state()\n        \n        return True\n    \n    def _is_valid_transition(self, from_state: TaskState, to_state: TaskState) -> bool:\n        \"\"\"Validate task state transitions\"\"\"\n        valid_transitions = {\n            TaskState.PENDING: [TaskState.IN_PROGRESS, TaskState.BLOCKED],\n            TaskState.IN_PROGRESS: [TaskState.COMPLETED, TaskState.FAILED, TaskState.BLOCKED],\n            TaskState.BLOCKED: [TaskState.PENDING, TaskState.IN_PROGRESS],\n            TaskState.COMPLETED: [],\n            TaskState.FAILED: [TaskState.PENDING]  # Allow retry\n        }\n        \n        return to_state in valid_transitions.get(from_state, [])\n    \n    def update_task_progress(self, task_id: str, progress: float, message: Optional[str] = None,\n                            resource_utilization: Optional[Dict[str, Any]] = None) -> bool:\n        \"\"\"Update task progress\"\"\"\n        if task_id not in self.tasks:\n            logger.error(f\"Task {task_id} not found\")\n            return False\n        \n        task = self.tasks[task_id]\n        task.progress = max(0.0, min(100.0, progress))\n        task.updated_at = datetime.now()\n        \n        # Record progress\n        progress_entry = TaskProgress(\n            task_id=task_id,\n            progress=progress,\n            timestamp=datetime.now(),\n            message=message,\n            resource_utilization=resource_utilization\n        )\n        \n        if task_id not in self.progress_trackers:\n            self.progress_trackers[task_id] = []\n        self.progress_trackers[task_id].append(progress_entry)\n        \n        self._add_audit_entry(task_id, \"progress_updated\", {\n            \"progress\": progress,\n            \"message\": message\n        })\n        self._save_state()\n        \n        return True\n    \n    def assign_task(self, task_id: str, agent_id: str) -> bool:\n        \"\"\"Assign task to an agent\"\"\"\n        if task_id not in self.tasks:\n            logger.error(f\"Task {task_id} not found\")\n            return False\n        \n        task = self.tasks[task_id]\n        task.assigned_agent = agent_id\n        task.updated_at = datetime.now()\n        \n        self._add_audit_entry(task_id, \"task_assigned\", {\"agent\": agent_id})\n        self._save_state()\n        \n        return True\n    \n    def get_task_dependencies(self, task_id: str) -> List[str]:\n        \"\"\"Get task dependencies that are not completed\"\"\"\n        if task_id not in self.tasks:\n            return []\n        \n        task = self.tasks[task_id]\n        incomplete_deps = []\n        \n        for dep_id in task.dependencies:\n            if dep_id in self.tasks and self.tasks[dep_id].state != TaskState.COMPLETED:\n                incomplete_deps.append(dep_id)\n        \n        return incomplete_deps\n    \n    def can_execute_task(self, task_id: str) -> bool:\n        \"\"\"Check if task can be executed (all dependencies completed)\"\"\"\n        return len(self.get_task_dependencies(task_id)) == 0\n    \n    def get_tasks_by_state(self, state: TaskState) -> List[Task]:\n        \"\"\"Get all tasks with a specific state\"\"\"\n        return [task for task in self.tasks.values() if task.state == state]\n    \n    def get_tasks_by_agent(self, agent_id: str) -> List[Task]:\n        \"\"\"Get all tasks assigned to an agent\"\"\"\n        return [task for task in self.tasks.values() if task.assigned_agent == agent_id]\n    \n    def get_task_progress_history(self, task_id: str) -> List[TaskProgress]:\n        \"\"\"Get progress history for a task\"\"\"\n        return self.progress_trackers.get(task_id, [])\n    \n    def _update_workflow_status(self, task_id: str):\n        \"\"\"Update workflow status based on task completion\"\"\"\n        for workflow in self.workflows.values():\n            if any(t.id == task_id for t in workflow.tasks):\n                # Check if all tasks in workflow are completed\n                all_completed = all(t.state == TaskState.COMPLETED for t in workflow.tasks)\n                any_failed = any(t.state == TaskState.FAILED for t in workflow.tasks)\n                \n                if all_completed:\n                    workflow.status = TaskState.COMPLETED\n                elif any_failed:\n                    workflow.status = TaskState.FAILED\n                else:\n                    workflow.status = TaskState.IN_PROGRESS\n                \n                workflow.updated_at = datetime.now()\n                self._add_audit_entry(workflow.id, \"workflow_status_updated\", {\"status\": workflow.status.value})\n    \n    def _add_audit_entry(self, task_id: str, action: str, details: Dict[str, Any], actor: Optional[str] = None):\n        \"\"\"Add entry to audit trail\"\"\"\n        entry = AuditTrailEntry(\n            task_id=task_id,\n            timestamp=datetime.now(),\n            action=action,\n            details=details,\n            actor=actor\n        )\n        self.audit_trail.append(entry)\n    \n    def get_audit_trail(self, task_id: Optional[str] = None) -> List[AuditTrailEntry]:\n        \"\"\"Get audit trail for a task or all tasks\"\"\"\n        if task_id:\n            return [entry for entry in self.audit_trail if entry.task_id == task_id]\n        return self.audit_trail\n    \n    def get_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get performance metrics for tasks\"\"\"\n        total_tasks = len(self.tasks)\n        if total_tasks == 0:\n            return {}\n        \n        completed_tasks = len(self.get_tasks_by_state(TaskState.COMPLETED))\n        failed_tasks = len(self.get_tasks_by_state(TaskState.FAILED))\n        in_progress_tasks = len(self.get_tasks_by_state(TaskState.IN_PROGRESS))\n        \n        success_rate = completed_tasks / total_tasks if total_tasks > 0 else 0\n        failure_rate = failed_tasks / total_tasks if total_tasks > 0 else 0\n        \n        # Calculate average completion time\n        completed_with_duration = [t for t in self.get_tasks_by_state(TaskState.COMPLETED) \n                                 if t.actual_duration is not None]\n        avg_completion_time = sum(t.actual_duration for t in completed_with_duration) / len(completed_with_duration) \\\n                             if completed_with_duration else 0\n        \n        return {\n            \"total_tasks\": total_tasks,\n            \"completed_tasks\": completed_tasks,\n            \"failed_tasks\": failed_tasks,\n            \"in_progress_tasks\": in_progress_tasks,\n            \"success_rate\": success_rate,\n            \"failure_rate\": failure_rate,\n            \"average_completion_time\": avg_completion_time\n        }\n    \n    def retry_failed_task(self, task_id: str) -> bool:\n        \"\"\"Retry a failed task\"\"\"\n        if task_id not in self.tasks:\n            logger.error(f\"Task {task_id} not found\")\n            return False\n        \n        task = self.tasks[task_id]\n        if task.state != TaskState.FAILED:\n            logger.error(f\"Task {task_id} is not in failed state\")\n            return False\n        \n        if task.retry_count >= task.max_retries:\n            logger.error(f\"Task {task_id} has reached maximum retries\")\n            return False\n        \n        task.retry_count += 1\n        task.failure_reason = None\n        self.update_task_state(task_id, TaskState.PENDING)\n        \n        self._add_audit_entry(task_id, \"task_retried\", {\"retry_count\": task.retry_count})\n        self._save_state()\n        \n        return True\n",
      "storage_integration": {
        "create_task_entry": true,
        "update_memory_blocks": true,
        "cc_sessions_compatible": true
      }
    },
    {
      "file": "/Users/fulvioventura/devflow/orchestration/task_state.py",
      "operation": "create",
      "content": "from enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\n\n@dataclass\nclass TaskStateInfo:\n    state: str\n    description: str\n    allowed_transitions: List[str]\n    is_terminal: bool = False\n\n# Define all possible task states with their properties\nTASK_STATES = {\n    \"pending\": TaskStateInfo(\n        state=\"pending\",\n        description=\"Task is waiting to be executed\",\n        allowed_transitions=[\"in_progress\", \"blocked\"],\n        is_terminal=False\n    ),\n    \"in_progress\": TaskStateInfo(\n        state=\"in_progress\",\n        description=\"Task is currently being executed\",\n        allowed_transitions=[\"completed\", \"failed\", \"blocked\"],\n        is_terminal=False\n    ),\n    \"completed\": TaskStateInfo(\n        state=\"completed\",\n        description=\"Task has been successfully completed\",\n        allowed_transitions=[],\n        is_terminal=True\n    ),\n    \"failed\": TaskStateInfo(\n        state=\"failed\",\n        description=\"Task execution failed\",\n        allowed_transitions=[\"pending\"],  # Allow retry\n        is_terminal=True\n    ),\n    \"blocked\": TaskStateInfo(\n        state=\"blocked\",\n        description=\"Task is blocked and cannot proceed\",\n        allowed_transitions=[\"pending\", \"in_progress\"],\n        is_terminal=False\n    )\n}\n\nclass TaskStateValidator:\n    @staticmethod\n    def is_valid_transition(from_state: str, to_state: str) -> bool:\n        \"\"\"Validate if a state transition is allowed\"\"\"\n        if from_state not in TASK_STATES:\n            return False\n        \n        return to_state in TASK_STATES[from_state].allowed_transitions\n    \n    @staticmethod\n    def is_terminal_state(state: str) -> bool:\n        \"\"\"Check if a state is terminal (cannot transition further)\"\"\"\n        if state not in TASK_STATES:\n            return False\n        \n        return TASK_STATES[state].is_terminal\n    \n    @staticmethod\n    def get_state_description(state: str) -> str:\n        \"\"\"Get human-readable description of a state\"\"\"\n        if state not in TASK_STATES:\n            return \"Unknown state\"\n        \n        return TASK_STATES[state].description\n    \n    @staticmethod\n    def get_allowed_transitions(state: str) -> List[str]:\n        \"\"\"Get list of allowed transitions from a state\"\"\"\n        if state not in TASK_STATES:\n            return []\n        \n        return TASK_STATES[state].allowed_transitions\n\nclass TaskProgressTracker:\n    def __init__(self):\n        self.progress_history: Dict[str, List[Dict[str, Any]]] = {}\n    \n    def record_progress(self, task_id: str, progress: float, \n                       message: Optional[str] = None,\n                       metadata: Optional[Dict[str, Any]] = None):\n        \"\"\"Record progress for a task\"\"\"\n        if task_id not in self.progress_history:\n            self.progress_history[task_id] = []\n        \n        record = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"progress\": progress,\n            \"message\": message,\n            \"metadata\": metadata or {}\n        }\n        \n        self.progress_history[task_id].append(record)\n    \n    def get_progress_history(self, task_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get progress history for a task\"\"\"\n        return self.progress_history.get(task_id, [])\n    \n    def get_current_progress(self, task_id: str) -> float:\n        \"\"\"Get current progress for a task\"\"\"\n        history = self.get_progress_history(task_id)\n        if not history:\n            return 0.0\n        \n        return history[-1][\"progress\"]\n    \n    def calculate_eta(self, task_id: str) -> Optional[float]:\n        \"\"\"Calculate estimated time to completion based on progress history\"\"\"\n        history = self.get_progress_history(task_id)\n        if len(history) < 2:\n            return None\n        \n        # Simple linear estimation based on last few points\n        recent_points = history[-5:] if len(history) > 5 else history\n        \n        # Calculate progress rate (progress per second)\n        first_point = recent_points[0]\n        last_point = recent_points[-1]\n        \n        progress_diff = last_point[\"progress\"] - first_point[\"progress\"]\n        time_diff = datetime.fromisoformat(last_point[\"timestamp\"]) - datetime.fromisoformat(first_point[\"timestamp\"])\n        \n        if time_diff.total_seconds() <= 0 or progress_diff <= 0:\n            return None\n        \n        progress_rate = progress_diff / time_diff.total_seconds()\n        remaining_progress = 100.0 - last_point[\"progress\"]\n        \n        return remaining_progress / progress_rate if progress_rate > 0 else None\n",
      "storage_integration": {
        "create_task_entry": true,
        "update_memory_blocks": true,
        "cc_sessions_compatible": true
      }
    },
    {
      "file": "/Users/fulvioventura/devflow/orchestration/progress_tracker.py",
      "operation": "create",
      "content": "from typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime, timedelta\nimport json\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass ProgressSnapshot:\n    timestamp: datetime\n    progress: float\n    message: Optional[str] = None\n    metadata: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass ResourceUtilization:\n    cpu_percent: Optional[float] = None\n    memory_mb: Optional[float] = None\n    disk_io: Optional[Dict[str, float]] = None\n    network_io: Optional[Dict[str, float]] = None\n    timestamp: datetime = None\n    \n    def __post_init__(self):\n        if self.timestamp is None:\n            self.timestamp = datetime.now()\n\n@dataclass\nclass PerformanceMetrics:\n    task_id: str\n    total_duration: Optional[float] = None  # in seconds\n    estimated_vs_actual: Optional[float] = None  # difference in seconds\n    resource_peaks: Optional[Dict[str, float]] = None\n    progress_consistency: Optional[float] = None  # 0-1 scale\n\nclass ProgressTracker:\n    def __init__(self):\n        self.progress_history: Dict[str, List[ProgressSnapshot]] = {}\n        self.resource_history: Dict[str, List[ResourceUtilization]] = {}\n        self.performance_metrics: Dict[str, PerformanceMetrics] = {}\n    \n    def record_progress(self, task_id: str, progress: float, \n                       message: Optional[str] = None,\n                       metadata: Optional[Dict[str, Any]] = None) -> bool:\n        \"\"\"Record progress for a task\"\"\"\n        try:\n            if task_id not in self.progress_history:\n                self.progress_history[task_id] = []\n            \n            snapshot = ProgressSnapshot(\n                timestamp=datetime.now(),\n                progress=max(0.0, min(100.0, progress)),\n                message=message,\n                metadata=metadata or {}\n            )\n            \n            self.progress_history[task_id].append(snapshot)\n            return True\n        except Exception as e:\n            logger.error(f\"Error recording progress for task {task_id}: {e}\")\n            return False\n    \n    def record_resource_utilization(self, task_id: str, \n                                  cpu_percent: Optional[float] = None,\n                                  memory_mb: Optional[float] = None,\n                                  disk_io: Optional[Dict[str, float]] = None,\n                                  network_io: Optional[Dict[str, float]] = None) -> bool:\n        \"\"\"Record resource utilization for a task\"\"\"\n        try:\n            if task_id not in self.resource_history:\n                self.resource_history[task_id] = []\n            \n            utilization = ResourceUtilization(\n                cpu_percent=cpu_percent,\n                memory_mb=memory_mb,\n                disk_io=disk_io,\n                network_io=network_io\n            )\n            \n            self.resource_history[task_id].append(utilization)\n            return True\n        except Exception as e:\n            logger.error(f\"Error recording resource utilization for task {task_id}: {e}\")\n            return False\n    \n    def get_progress_history(self, task_id: str) -> List[ProgressSnapshot]:\n        \"\"\"Get complete progress history for a task\"\"\"\n        return self.progress_history.get(task_id, [])\n    \n    def get_current_progress(self, task_id: str) -> float:\n        \"\"\"Get current progress percentage for a task\"\"\"\n        history = self.get_progress_history(task_id)\n        if not history:\n            return 0.0\n        \n        return history[-1].progress\n    \n    def get_resource_history(self, task_id: str) -> List[ResourceUtilization]:\n        \"\"\"Get resource utilization history for a task\"\"\"\n        return self.resource_history.get(task_id, [])\n    \n    def calculate_eta(self, task_id: str) -> Optional[timedelta]:\n        \"\"\"Calculate estimated time to completion\"\"\"\n        history = self.get_progress_history(task_id)\n        if len(history) < 2:\n            return None\n        \n        # Use last 10 points for calculation\n        recent_points = history[-10:] if len(history) > 10 else history\n        \n        # Calculate progress rate\n        first_point = recent_points[0]\n        last_point = recent_points[-1]\n        \n        progress_diff = last_point.progress - first_point.progress\n        time_diff = (last_point.timestamp - first_point.timestamp).total_seconds()\n        \n        if time_diff <= 0 or progress_diff <= 0:\n            return None\n        \n        progress_rate = progress_diff / time_diff  # progress per second\n        remaining_progress = 100.0 - last_point.progress\n        \n        if progress_rate > 0:\n            eta_seconds = remaining_progress / progress_rate\n            return timedelta(seconds=eta_seconds)\n        \n        return None\n    \n    def calculate_performance_metrics(self, task_id: str) -> Optional[PerformanceMetrics]:\n        \"\"\"Calculate performance metrics for a completed task\"\"\"\n        progress_history = self.get_progress_history(task_id)\n        if len(progress_history) < 2:\n            return None\n        \n        # Calculate total duration\n        first_timestamp = progress_history[0].timestamp\n        last_timestamp = progress_history[-1].timestamp\n        total_duration = (last_timestamp - first_timestamp).total_seconds()\n        \n        # Calculate resource peaks\n        resource_history = self.get_resource_history(task_id)\n        resource_peaks = {}\n        \n        if resource_history:\n            cpu_values = [r.cpu_percent for r in resource_history if r.cpu_percent is not None]\n            memory_values = [r.memory_mb for r in resource_history if r.memory_mb is not None]\n            \n            if cpu_values:\n                resource_peaks[\"cpu_peak\"] = max(cpu_values)\n            if memory_values:\n                resource_peaks[\"memory_peak_mb\"] = max(memory_values)\n        \n        # Calculate progress consistency (how smooth the progress was)\n        progress_values = [p.progress for p in progress_history]\n        if len(progress_values) > 1:\n            # Calculate standard deviation of progress increments\n            increments = [progress_values[i] - progress_values[i-1] \n                         for i in range(1, len(progress_values))]\n            if increments:\n                avg_increment = sum(increments) / len(increments)\n                variance = sum((inc - avg_increment) ** 2 for inc in increments) / len(increments)\n                std_dev = variance ** 0.5\n                # Convert to consistency score (0-1, higher is better)\n                consistency = max(0, 1 - (std_dev / 50))  # Normalize assuming 50% std dev is bad\n            else:\n                consistency = 1.0\n        else:\n            consistency = 1.0\n        \n        metrics = PerformanceMetrics(\n            task_id=task_id,\n            total_duration=total_duration,\n            resource_peaks=resource_peaks or {},\n            progress_consistency=consistency\n        )\n        \n        self.performance_metrics[task_id] = metrics\n        return metrics\n    \n    def get_performance_metrics(self, task_id: str) -> Optional[PerformanceMetrics]:\n        \"\"\"Get cached performance metrics for a task\"\"\"\n        return self.performance_metrics.get(task_id)\n    \n    def get_progress_trend(self, task_id: str, window_size: int = 5) -> Optional[float]:\n        \"\"\"Calculate progress trend (positive = accelerating, negative = decelerating)\"\"\"\n        history = self.get_progress_history(task_id)\n        if len(history) < window_size * 2:\n            return None\n        \n        # Compare recent progress rate to earlier rate\n        recent_points = history[-window_size:]\n        earlier_points = history[-window_size*2:-window_size]\n        \n        # Calculate recent rate\n        recent_time_diff = (recent_points[-1].timestamp - recent_points[0].timestamp).total_seconds()\n        recent_progress_diff = recent_points[-1].progress - recent_points[0].progress\n        recent_rate = recent_progress_diff / recent_time_diff if recent_time_diff > 0 else 0\n        \n        # Calculate earlier rate\n        earlier_time_diff = (earlier_points[-1].timestamp - earlier_points[0].timestamp).total_seconds()\n        earlier_progress_diff = earlier_points[-1].progress - earlier_points[0].progress\n        earlier_rate = earlier_progress_diff / earlier_time_diff if earlier_time_diff > 0 else 0\n        \n        return recent_rate - earlier_rate  # Positive = acceleration\n    \n    def export_progress_data(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Export all progress data for a task as a serializable dict\"\"\"\n        return {\n            \"progress_history\": [\n                {\n                    \"timestamp\": p.timestamp.isoformat(),\n                    \"progress\": p.progress,\n                    \"message\": p.message,\n                    \"metadata\": p.metadata\n                }\n                for p in self.get_progress_history(task_id)\n            ],\n            \"resource_history\": [\n                {\n                    \"timestamp\": r.timestamp.isoformat(),\n                    \"cpu_percent\": r.cpu_percent,\n                    \"memory_mb\": r.memory_mb,\n                    \"disk_io\": r.disk_io,\n                    \"network_io\": r.network_io\n                }\n                for r in self.get_resource_history(task_id)\n            ],\n            \"performance_metrics\": asdict(self.get_performance_metrics(task_id)) if task_id in self.performance_metrics else None\n        }\n",
      "storage_integration": {
        "create_task_entry": true,
        "update_memory_blocks": true,
        "cc_sessions_compatible": true
      }
    },
    {
      "file": "/Users/fulvioventura/devflow/orchestration/failure_recovery.py",
      "operation": "create",
      "content": "from typing import Dict, List, Optional, Callable, Any\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nimport logging\nimport json\n\nlogger = logging.getLogger(__name__)\n\nclass FailureType(Enum):\n    TRANSIENT = \"transient\"  # Temporary issues that may resolve\n    PERMANENT = \"permanent\"  # Issues requiring intervention\n    RESOURCE = \"resource\"    # Resource exhaustion\n    DEPENDENCY = \"dependency\" # Dependency failure\n    CONFIGURATION = \"configuration\" # Misconfiguration\n\nclass RecoveryStrategy(Enum):\n    RETRY = \"retry\"\n    ESCALATE = \"escalate\"\n    FALLBACK = \"fallback\"\n    SKIP = \"skip\"\n    BLOCK = \"block\"\n\n@dataclass\nclass FailureRecord:\n    task_id: str\n    failure_type: FailureType\n    error_message: str\n    timestamp: datetime\n    retry_count: int = 0\n    recovery_strategy: Optional[RecoveryStrategy] = None\n    recovery_action_taken: Optional[str] = None\n    recovery_timestamp: Optional[datetime] = None\n    is_resolved: bool = False\n\n@dataclass\nclass RetryPolicy:\n    max_retries: int = 3\n    backoff_factor: float = 2.0\n    base_delay: float = 1.0  # seconds\n    max_delay: float = 300.0  # seconds\n    jitter: bool = True\n\n@dataclass\nclass EscalationRule:\n    failure_count_threshold: int\n    time_window: timedelta\n    escalation_target: str  # e.g., \"admin\", \"supervisor\", email address\n    notification_message: str\n\nclass FailureRecoverySystem:\n    def __init__(self):\n        self.failure_records: Dict[str, List[FailureRecord]] = {}\n        self.retry_policies: Dict[str, RetryPolicy] = {}\n        self.escalation_rules: List[EscalationRule] = []\n        self.failure_patterns: Dict[str, int] = {}  # Simple pattern tracking\n        self.recovery_handlers: Dict[RecoveryStrategy, List[Callable]] = {\n            RecoveryStrategy.RETRY: [],\n            RecoveryStrategy.ESCALATE: [],\n            RecoveryStrategy.FALLBACK: [],\n            RecoveryStrategy.SKIP: [],\n            RecoveryStrategy.BLOCK: []\n        }\n    \n    def register_recovery_handler(self, strategy: RecoveryStrategy, handler: Callable):\n        \"\"\"Register a handler for a recovery strategy\"\"\"\n        if strategy not in self.recovery_handlers:\n            self.recovery_handlers[strategy] = []\n        self.recovery_handlers[strategy].append(handler)\n    \n    def set_retry_policy(self, task_id: str, policy: RetryPolicy):\n        \"\"\"Set retry policy for a specific task\"\"\"\n        self.retry_policies[task_id] = policy\n    \n    def add_escalation_rule(self, rule: EscalationRule):\n        \"\"\"Add an escalation rule\"\"\"\n        self.escalation_rules.append(rule)\